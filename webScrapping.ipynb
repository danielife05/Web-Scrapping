{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Escuela Politécnica Nacional\n",
    "## Facultad de Ingeniería en Sistemas\n",
    "## Materia: Métodos Numéricos\n",
    "## Nombre: Daniel Ismael Flores Espín"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KO: 62.84\n",
      "AAPL: 258.20\n",
      "MSFT: 439.33\n",
      "TSLA: 462.28\n",
      "GOOGL: 196.11\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def obtener_datos_financieros(ticker):\n",
    "    url = f\"https://finance.yahoo.com/quote/{ticker}?p={ticker}\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        precio_actual = soup.find(\"fin-streamer\", {\"data-field\": \"regularMarketPrice\"})\n",
    "        if precio_actual:\n",
    "            return precio_actual.text\n",
    "        else:\n",
    "            return \"Precio no disponible\"\n",
    "    else:\n",
    "        return f\"Error al acceder a la página: {response.status_code}\"\n",
    "\n",
    "# Lista de empresas\n",
    "tickers = [\"KO\", \"AAPL\", \"MSFT\", \"TSLA\", \"GOOGL\"]\n",
    "\n",
    "for ticker in tickers:\n",
    "    precio = obtener_datos_financieros(ticker)\n",
    "    print(f\"{ticker}: {precio}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerías utilizadas:\n",
    "\n",
    "1. **requests**:\n",
    "   - Es una biblioteca en Python diseñada para hacer solicitudes HTTP de manera simple.\n",
    "   - En el ejemplo, se usa para realizar una solicitud GET a la página de Yahoo Finance y obtener el contenido HTML de la URL que corresponde a un ticker específico.\n",
    "\n",
    "2. **BeautifulSoup**:\n",
    "   - Es una biblioteca utilizada para analizar y extraer datos de contenido HTML o XML.\n",
    "   - En este caso, se utiliza para analizar el contenido HTML de la página web y localizar elementos específicos relacionados con el precio del mercado regular de una acción.\n",
    "\n",
    "\n",
    "### Explicación de código: \n",
    "#### Función: obtener_datos_financieros\n",
    "- **Parámetros**:\n",
    "  - Recibe un argumento ticker, que es el símbolo bursátil de la empresa (por ejemplo, \"KO\" para Coca-Cola).\n",
    "  \n",
    "- **Flujo de la función**:\n",
    "  1. **Construcción de la URL**:\n",
    "     - Forma la URL de Yahoo Finance utilizando el ticker proporcionado, por ejemplo, https://finance.yahoo.com/quote/AAPL?p=AAPL para Apple.\n",
    "  2. **Solicitud GET**:\n",
    "     - Usa requests.get(url) para obtener el contenido HTML de la página web.\n",
    "     - Verifica si la respuesta tiene un código de estado 200 (lo que indica éxito).\n",
    "  3. **Análisis del contenido HTML**:\n",
    "     - Usa BeautifulSoup para procesar el contenido HTML de la respuesta.\n",
    "     - Busca en el documento HTML un elemento <fin-streamer> que tiene un atributo data-field igual a \"regularMarketPrice\". Este elemento contiene el precio actual de la acción.\n",
    "  4. **Devolver el precio**:\n",
    "     - Si encuentra el precio, devuelve el texto de ese elemento (precio actual).\n",
    "     - Si no, informa que el precio no está disponible.\n",
    "  5. **Manejo de errores**:\n",
    "     - Si la solicitud HTTP falla (no es código 200), devuelve un mensaje de error con el código de estado.\n",
    "\n",
    "#### Lista de tickers:\n",
    "- Define una lista con los símbolos bursátiles de varias empresas: [\"KO\", \"AAPL\", \"MSFT\", \"TSLA\", \"GOOGL\"].\n",
    "\n",
    "#### Bucle para consultar precios:\n",
    "- Itera por cada ticker en la lista.\n",
    "- Llama a la función obtener_datos_financieros para obtener el precio de la acción correspondiente.\n",
    "- Imprime el ticker junto con el precio obtenido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KO: 62.84\n",
      "AAPL: 258.20\n",
      "MSFT: 439.33\n",
      "TSLA: 462.28\n",
      "GOOGL: 196.11\n"
     ]
    }
   ],
   "source": [
    "import mechanicalsoup\n",
    "\n",
    "# Lista de empresas\n",
    "tickers = [\"KO\", \"AAPL\", \"MSFT\", \"TSLA\", \"GOOGL\"]\n",
    "\n",
    "navegador = mechanicalsoup.StatefulBrowser()\n",
    "\n",
    "for t in tickers:\n",
    "    url = f\"https://finance.yahoo.com/quote/{t}\"\n",
    "\n",
    "    navegador.open(url)\n",
    "    pagina = navegador.get_current_page()\n",
    "    etiqueta_precio = pagina.select_one('fin-streamer[data-field=\"regularMarketPrice\"]')\n",
    "    \n",
    "    if etiqueta_precio:\n",
    "        precio_actual = etiqueta_precio.text\n",
    "        print(f\"{t}: {precio_actual}\")\n",
    "    else:\n",
    "        print(f\"No se encontró el elemento con el precio para {t}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Librería utilizada:**\n",
    "\n",
    "1. **mechanicalsoup**:\n",
    "   - Es una biblioteca en Python que combina la funcionalidad de BeautifulSoup (para analizar contenido HTML) y un navegador simulado para realizar solicitudes HTTP y mantener el estado entre solicitudes.\n",
    "   - Permite interactuar con páginas web de manera sencilla, incluyendo formularios y navegación entre páginas.\n",
    "   - En este ejemplo, se usa para abrir páginas de Yahoo Finance y extraer el precio de mercado regular de las acciones.\n",
    "\n",
    "### Explicación de Código:\n",
    "\n",
    "#### **Configuración del navegador:**\n",
    "- Se crea una instancia de un navegador con mechanicalsoup.StatefulBrowser(). Este navegador simulado permite abrir URLs, mantener cookies y analizar el contenido HTML de las páginas.\n",
    "\n",
    "#### **Lista de tickers:**\n",
    "- Define una lista con los símbolos bursátiles de las empresas (por ejemplo, \"KO\" para Coca-Cola y \"AAPL\" para Apple).\n",
    "\n",
    "#### **Bucle para extraer datos:**\n",
    "1. **Construcción de la URL**:\n",
    "   - Para cada ticker en la lista, forma la URL específica de Yahoo Finance, por ejemplo, https://finance.yahoo.com/quote/AAPL para Apple.\n",
    "2. **Abrir la página web**:\n",
    "   - Usa navegador.open(url) para acceder a la URL.\n",
    "   - El contenido de la página actual se almacena en pagina utilizando navegador.get_current_page().\n",
    "3. **Buscar el precio de la acción**:\n",
    "   - Utiliza el método select_one de BeautifulSoup para buscar un elemento <fin-streamer> con el atributo data-field=\"regularMarketPrice\", que contiene el precio actual de la acción.\n",
    "   - Si encuentra la etiqueta, extrae el precio con .text.\n",
    "4. **Mostrar el resultado**:\n",
    "   - Imprime el ticker junto con el precio encontrado.\n",
    "   - Si no encuentra el precio, imprime un mensaje indicando que el elemento no fue localizado.\n",
    "\n",
    "### **Ventajas de usar mechanicalsoup:**\n",
    "- **Manejo del estado**:\n",
    "  - Al ser un navegador con estado, puede manejar cookies, encabezados y autenticación automáticamente, algo que requests no hace directamente.\n",
    "- **Integración con BeautifulSoup**:\n",
    "  - Permite acceder al contenido HTML y analizarlo fácilmente para extraer información específica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen varias bibliotecas para hacer web scraping porque cada una está diseñada para satisfacer necesidades específicas, manejar diferentes niveles de complejidad y adaptarse a casos de uso variados.\n",
    "\n",
    "No todos los proyectos de scraping son iguales. Algunos solo requieren descargar y analizar contenido HTML simple, mientras que otros necesitan manejar JavaScript dinámico, autenticación, o navegación compleja. Diferentes bibliotecas ofrecen herramientas especializadas para cada caso:\n",
    "- **requests + BeautifulSoup**: Perfecto para proyectos simples donde solo necesitas extraer datos de HTML estático.\n",
    "- **Selenium**: Ideal para manejar sitios con contenido dinámico generado por JavaScript o para automatizar interacciones como clics y entradas de texto.\n",
    "- **mechanicalsoup**: Excelente para manejar formularios y mantener el estado sin la complejidad de un navegador completo.\n",
    "- **Scrapy**: Diseñada para proyectos grandes y estructurados, con características como crawling avanzado y manejo eficiente de datos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
